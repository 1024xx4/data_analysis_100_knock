{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 9章 潜在顧客を把握するための画像認識\n",
    "\n",
    "ここでは、カメラから取得した映像を用いて画像認識を行い、\n",
    "必要な情報を取得するための流れを学ぶことで、\n",
    "画像認識をビジネス現場で応用するイメージをつかみます。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "画像 Data を表示する"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画像幅: 1920\n",
      "画像高さ: 1440\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('sample_code/chapter_9/img/img01.jpg')\n",
    "height, width = img.shape[:2]\n",
    "print(f'画像幅: {str(width)}')\n",
    "print(f'画像高さ: {str(height)}')\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "映像 Data を表示する"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 情報取得\n",
    "cap = cv2.VideoCapture('sample_code/chapter_9/mov/mov01.avi')\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f'画像幅: {str(width)}')\n",
    "print(f'画像高さ: {str(height)}')\n",
    "print(f'総フレーム数: {str(count)}')\n",
    "print(f'FPS: {str(fps)}')\n",
    "\n",
    "# 出力\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "映像を画像に分割し、保存する"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('sample_code/chapter_9/mov/mov01.avi')\n",
    "num = 0\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('frame', frame)\n",
    "        filepath = f'snapshot/snapshot_{str(num)}.jpg'\n",
    "        cv2.imwrite(filepath, frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    num = num + 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 準備\n",
    "hog = cv2.HOGDescriptor() # 宣言\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector()) # ヒトのモデルを与える\n",
    "hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold': 0, 'finalThreshold': 5}\n",
    "\n",
    "# 検出\n",
    "img = cv2.imread('sample_code/chapter_9/img/img01.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 読み込んだ画像をモノクロにする\n",
    "human, r = hog.detectMultiScale(gray, **hogParams) # 人の検出を実行する\n",
    "if len(human) > 0:\n",
    "    for (x, y, w, h) in human:\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 255), 3) # human に格納された位置情報から四角形を描く\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 準備\n",
    "cascade_file = 'sample_code/chapter_9/haarcascade_frontalface_alt.xml' # 宣言 & 正面顔を認識する Model を与える。\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "# 検出\n",
    "img = cv2.imread('sample_code/chapter_9/img/img02.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "face_list = cascade.detectMultiScale(gray, minSize=(50, 50)) # 顔の位置を検出\n",
    "\n",
    "# 検出した顔に印を付ける\n",
    "for (x, y, w, h) in face_list:\n",
    "    color = (0, 0, 225)\n",
    "    pen_w = 3\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), color, thickness=pen_w)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imwrite('temp.jpg', img)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "顔方位: 0.06456096931747406（角度: 3.6990710631648662度）\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import math\n",
    "\n",
    "# 準備\n",
    "predictor = dlib.shape_predictor('sample_code/chapter_9/shape_predictor_68_face_landmarks.dat') # 68点の顔器官 Model の読み込み\n",
    "detector = dlib.get_frontal_face_detector() # 顔正面の Model の読み込み\n",
    "\n",
    "# 検出\n",
    "img = cv2.imread('sample_code/chapter_9/img/img02.jpg')\n",
    "dets = detector(img, 1) # 写真から正面顔を検出\n",
    "\n",
    "for k, d in enumerate(dets):\n",
    "    shape = predictor(img, d) # 写真から検出した正面顔に含まれる68点の顔器官を検出。\n",
    "\n",
    "    # 顔領域の表示\n",
    "    color_f = (0, 0, 225)\n",
    "    color_l_out = (255, 0, 0)\n",
    "    color_l_in = (0, 255, 0)\n",
    "    line_w = 3\n",
    "    circle_r = 3\n",
    "    fontType = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontSize = 1\n",
    "    cv2.rectangle(img, (d.left(), d.top()), (d.right(), d.bottom()), color_f, line_w)\n",
    "    cv2.putText(img, str(k), (d.left(), d.top()) , fontType, fontSize, color_f, line_w)\n",
    "\n",
    "    # 重心を導出する箱を用意\n",
    "    num_of_points_out = 17\n",
    "    num_of_points_in = shape.num_parts - num_of_points_out\n",
    "    gx_out = 0\n",
    "    gy_out = 0\n",
    "    gx_in = 0\n",
    "    gy_in = 0\n",
    "    for shape_point_count in range(shape.num_parts):\n",
    "        shape_point = shape.part(shape_point_count)\n",
    "        # print(f'顔器官 No. {shape_point_count} 座標位置: {shape_point.x}, {shape_point.y}')\n",
    "        # 器官ごとに描画\n",
    "        if shape_point_count < num_of_points_out:\n",
    "            cv2.circle(img, (shape_point.x, shape_point.y), circle_r, color_l_out, line_w)\n",
    "            gx_out = gx_out + shape_point.x / num_of_points_out\n",
    "            gy_out = gy_out + shape_point.y / num_of_points_out\n",
    "        else:\n",
    "            cv2.circle(img, (shape_point.x, shape_point.y), circle_r, color_l_in, line_w)\n",
    "            gx_in = gx_in + shape_point.x / num_of_points_in\n",
    "            gy_in = gy_in + shape_point.y / num_of_points_in\n",
    "    # 重心位置を描画\n",
    "    cv2.circle(img, (int(gx_out), int(gy_out)), circle_r, (0, 0, 255), line_w)\n",
    "    cv2.circle(img, (int(gx_in), int(gy_in)), circle_r, (0, 0, 0), line_w)\n",
    "\n",
    "    # 顔の方位を計算\n",
    "    theta = math.asin(2 * (gx_in - gx_out) / (d.right() - d.left()))\n",
    "    radian = theta * 180 / math.pi\n",
    "    print(f'顔方位: {theta}（角度: {radian}度）')\n",
    "\n",
    "    # 顔方位を表示\n",
    "    if radian < 0:\n",
    "        textPrefix = '   left '\n",
    "    else:\n",
    "        textPrefix = '   right '\n",
    "    textShow = textPrefix + str(round(abs(radian), 1)) + ' deg.'\n",
    "    cv2.putText(img, textShow, (d.left(), d.top()), fontType, fontSize, color_f, line_w)\n",
    "\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imwrite('dump/temp_2.jpg', img)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}